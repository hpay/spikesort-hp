{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting KILOSORT2_PATH environment variable for subprocess calls to: D:\\hannah\\Dropbox\\code\\spikesort\\kilosort-2.0\n",
      "Setting IRONCLUST_PATH environment variable for subprocess calls to: D:\\hannah\\Dropbox\\code\\spikesort\\ironclust\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscriptv4nas5t1\\script.bat\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscript94yhce_h\\script.bat\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscriptv2uhh7wh\\script.bat\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscriptm0hu2rek\\script.bat\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscripteedxzj8o\\script.bat\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscript4st4el1c\\script.bat\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscript8slmz2k4\\script.bat\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscriptmfojqj62\\script.bat\n",
      "['ironclust', 'kilosort2', 'spykingcircus2', 'tridesclous', 'tridesclous2']\n",
      "SpikeInterface version: 0.95.1.dev0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import platform\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.full as si\n",
    "\n",
    "\n",
    "\n",
    "# Add path to kilosort2 and ironclust repos\n",
    "si.Kilosort2Sorter.set_kilosort2_path(Path.resolve(Path('../../Kilosort-2.0')))\n",
    "si.IronClustSorter.set_ironclust_path(Path.resolve(Path('../../ironclust')))\n",
    "\n",
    "print(ss.installed_sorters())\n",
    "print(f\"SpikeInterface version: {si.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false!\n",
      "..\\results\\kilosort2_output\n",
      "D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\kilosort2_output\n",
      "D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\kilosort2_output\n"
     ]
    }
   ],
   "source": [
    "path_test = Path('..','results', 'kilosort2'+'_output')\n",
    "if path_test.exists(): print('true!')\n",
    "else: print('false!')\n",
    "print(path_test)\n",
    "print(Path.resolve(path_test))\n",
    "\n",
    "path_test = Path.resolve(path_test)\n",
    "print(path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make toy example recording data in the results folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy data already exists\n",
      "D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\toy_example_recording\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path.resolve(Path('../results/toy_example_recording'))\n",
    "\n",
    "if not data_folder.exists():\n",
    "    rec, sorting = si.toy_example(num_segments=1, duration=100, seed=1, num_channels=16, num_columns=2)\n",
    "    rec.save(folder=data_folder)\n",
    "    print('Created toy data')\n",
    "else:\n",
    "    print('Toy data already exists')\n",
    "print(data_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the recording extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryFolderRecording: 16 channels - 1 segments - 30.0kHz - 100.000s"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = si.load_extractor(data_folder)\n",
    "rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Kilosort on the test data: \n",
    "\n",
    "Note: make sure your startup.m file in Matlab doesn't change the current directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\kilosort2_output\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscript89j9o9w0\\script.bat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c3783f4a6148b5b1ed99689cdd95e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscriptepuf21jb\\script.bat\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscript49guip0l\\script.bat\n",
      "RUNNING SHELL SCRIPT: D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\kilosort2_output\\run_kilosort2.bat\n",
      "\n",
      "\n",
      "(si_env) d:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\scripts>D:\n",
      "\n",
      "\n",
      "\n",
      "(si_env) d:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\scripts>cd D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\kilosort2_output \n",
      "\n",
      "\n",
      "\n",
      "(si_env) D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\kilosort2_output>matlab -nosplash -wait -r \"kilosort2_master('D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\kilosort2_output', 'D:\\hannah\\Dropbox\\code\\spikesort\\kilosort-2.0')\" \n",
      "\n",
      "kilosort2 run time 37.17s\n",
      "D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\kilosort2_waveforms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WaveformExtractor: 16 channels - 11 units - 1 segments\n",
       "  before:90 after:120 n_per_units:500"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run sorter\n",
    "sorter_name = 'kilosort2'\n",
    "output_folder = Path.resolve(Path('..','results', sorter_name+'_output'))\n",
    "print(output_folder)\n",
    "sorting = si.run_sorter(sorter_name, rec, output_folder, verbose=True, remove_existing_folder=True)\n",
    "\n",
    "# Get waveforms\n",
    "waveform_folder = Path.resolve(Path('..','results', sorter_name+'_waveforms'))\n",
    "print(waveform_folder)\n",
    "si.extract_waveforms(rec, sorting, waveform_folder,\n",
    "    n_jobs=1, total_memory=\"10M\", max_spikes_per_unit=500, return_scaled=False, overwrite=True)\n",
    "\n",
    "# Export to Phy\n",
    "we = si.WaveformExtractor.load_from_folder(waveform_folder)\n",
    "phy_folder =  Path.resolve(Path('..','results', sorter_name+'_phy'))\n",
    "print(phy_folder)\n",
    "si.export_to_phy(we, output_folder=phy_folder, verbose=False, remove_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscriptvvh17udx\\script.bat\n",
      "Warning! The recording is already filtered, but ironclust filter is enabled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feef228397d942c9b2e18432cae7ca5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels = 16, timepoints = 3000000, duration = 1.6666666666666667 minutes\n",
      "Creating argfile.txt...\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscriptt8osy_8q\\script.bat\n",
      "Running ironclust in D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp...\n",
      "RUNNING SHELL SCRIPT: C:\\Users\\Hannah\\AppData\\Local\\Temp\\tmp_shellscriptpfz7fq6x\\script.bat\n",
      "RUNNING SHELL SCRIPT: D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\run_ironclust.bat\n",
      "\n",
      "\n",
      "(si_env) d:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\scripts>D:\n",
      "\n",
      "\n",
      "\n",
      "(si_env) d:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\scripts>cd D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp \n",
      "\n",
      "\n",
      "\n",
      "(si_env) D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp>matlab -nosplash -wait -log -r run_ironclust \n",
      "\n",
      "Welcome to MATLAB!!! <^.^>\n",
      "\n",
      "Edit startup.m to change startup options.\n",
      "\n",
      "===================================================\n",
      "\n",
      "IronClust Version: 2\n",
      "\n",
      "===================================================\n",
      "\n",
      "Removed 0 lock(s).\n",
      "\n",
      "Running irc2.m (5.9.8)\n",
      "\n",
      "Created D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp\\raw_geom.prm\n",
      "\n",
      "Read D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\ironclust_dataset\\raw.mda (1/1), took 0.1s (1326.6 MB/s, 192.0 MB)\n",
      "\n",
      "\tget_prinvec_: took 0.2s\n",
      "\n",
      "\tDetecting 1/1: 21443 spikes found (5081.3 spikes/s, 45.5 MB/s, took 4.2 s)\n",
      "\n",
      "Detection took 4.6s and used 2.005 GiB (fParfor=0, fGpu=1)\n",
      "\n",
      "Saving a struct to D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp\\detect_9f9d5782701ef0a4c201ab8b205750a2\\detect_irc.mat: took 0.1s.\n",
      "\n",
      "Clustering\n",
      "\n",
      "Calculating drift similarity...\n",
      "\n",
      "\ttook 0.0s\n",
      "\n",
      "sort_page_: calculating Rho...\n",
      "\n",
      "Page 1/1 ................ took 1.5s\n",
      "\n",
      "calculating Rho took 1.5s\n",
      "\n",
      "sort_page_: calculating Delta...\n",
      "\n",
      "Page 1/1 ................ took 0.4s\n",
      "\n",
      "calculating Delta took 0.4s\n",
      "\n",
      "sort_long_: took 1.9s (fGpu=1, fParfor=0)\n",
      "\n",
      "Saving a struct to D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp\\detect_9f9d5782701ef0a4c201ab8b205750a2\\sort_b5e8be3adbd834d6471ca94e5d41d629\\sort_irc.mat: took 0.1s.\n",
      "\n",
      "\n",
      "\n",
      "auto-merging...\n",
      "\n",
      "\tpostCluster_...\n",
      "\n",
      "\tcell2map_: ... nRepeat=4, took 0.0s\n",
      "\n",
      "\tnRepeat:1, n0=0\n",
      "\n",
      "\tpostCluster_: Pre-merged 42->16->16 clusters, took 0.1s\n",
      "\n",
      "\tisolation_score_: took 0.1s\n",
      "\n",
      "\tcell2map_: .. nRepeat=3, took 0.0s\n",
      "\n",
      "\tknn_overlap_merge_: 16->11 units\n",
      "\n",
      "Removed 333/21443 (1.6%) duplicate spikes, took 0.0s\n",
      "\n",
      "\tMerging templates...\n",
      "\n",
      "\t................\n",
      "\n",
      "\tcell2map_: . nRepeat=2, took 0.0s\n",
      "\n",
      "\tMerged waveforms (11->11->8), took 0.4s\n",
      "\n",
      "Removed 0/1883 (0.0%) duplicate spikes, took 0.0s\n",
      "\n",
      "\tauto-merging took 0.7s (fGpu=1, fParfor=0)\n",
      "\n",
      "\tisolation_score_: took 0.0s\n",
      "\n",
      "Wrote to D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp\\detect_9f9d5782701ef0a4c201ab8b205750a2\\sort_b5e8be3adbd834d6471ca94e5d41d629\\auto_f83832cfc7a58d1733a09ba4456e6515\\firings.mda, took 0.0s\n",
      "\n",
      "Saving a struct to D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp\\detect_9f9d5782701ef0a4c201ab8b205750a2\\sort_b5e8be3adbd834d6471ca94e5d41d629\\auto_f83832cfc7a58d1733a09ba4456e6515\\auto_irc.mat: took 0.1s.\n",
      "\n",
      "\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Summary of D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp\\raw_geom.prm\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Recording format\n",
      "\n",
      "    Recording file:         D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\ironclust_dataset\\raw.mda\n",
      "\n",
      "    Probe file:             D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\ironclust_dataset\\geom.csv\n",
      "\n",
      "    Recording Duration:     100.0s\n",
      "\n",
      "    Data Type:              single\n",
      "\n",
      "    #Channels in file:      16\n",
      "\n",
      "    #Sites:                 16\n",
      "\n",
      "    #Shanks:                1\n",
      "\n",
      "Pre-processing\n",
      "\n",
      "    Filter type:            bandpass\n",
      "\n",
      "    Filter range (Hz):      [300.0, 8000.0]\n",
      "\n",
      "    Matched Filter:         0\n",
      "\n",
      "    Common ref:             trimmean\n",
      "\n",
      "    Whiten:                 0\n",
      "\n",
      "    FFT threshold:          8\n",
      "\n",
      "    blank threshold:        0\n",
      "\n",
      "Events\n",
      "\n",
      "    #Spikes:                21443\n",
      "\n",
      "    Feature extracted:      gpca\n",
      "\n",
      "    #Sites/event:           9\n",
      "\n",
      "    maxDist_site_um:        50\n",
      "\n",
      "    maxDist_site_spk_um:    100\n",
      "\n",
      "    spkLim_ms:              [-0.250, 0.750]\n",
      "\n",
      "    #PC/chan:               9\n",
      "\n",
      "Cluster\n",
      "\n",
      "    #Clusters:              8\n",
      "\n",
      "    #Unique events:         1883\n",
      "\n",
      "    min. spk/clu:           30\n",
      "\n",
      "    Cluster method:         drift-knn\n",
      "\n",
      "    knn:                    30\n",
      "\n",
      "    step_sec_drift:         20.0s\n",
      "\n",
      "    batch_sec_drift:        300.0s\n",
      "\n",
      "Auto-merge\n",
      "\n",
      "    merge_overlap_thresh:   0.950\n",
      "\n",
      "    delta_cut:              1.000\n",
      "\n",
      "    merge_thresh_cc:        1.000\n",
      "\n",
      "    maxWavCor:              0.985\n",
      "\n",
      "Runtime (s)\n",
      "\n",
      "    Detect + feature (s):   4.6s\n",
      "\n",
      "    Cluster runtime (s):    2.0s\n",
      "\n",
      "    merge runtime (s):      0.7s\n",
      "\n",
      "    Total runtime (s):      7.3s\n",
      "\n",
      "    Runtime speed:          x13.8 realtime\n",
      "\n",
      "    Processing speed:       2952.0 spikes/s\n",
      "\n",
      "memory usage (GiB):         2.005\n",
      "\n",
      "    detect:                 2.005\n",
      "\n",
      "    sort:                   1.956\n",
      "\n",
      "    auto-merge:             1.985\n",
      "\n",
      "Execution\n",
      "\n",
      "    irc2 version:           5.9.8\n",
      "\n",
      "    fGpu (GPU use):         1\n",
      "\n",
      "    fParfor (parfor use):   0\n",
      "\n",
      "    fLargeRecording:        0\n",
      "\n",
      "    Parameter file:         D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp\\raw_geom.prm\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Clustering result wrote to D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_output\\tmp/firings.mda\n",
      "\n",
      "#SF-SORTER-RUNTIME#14.780#\n",
      "\n",
      "Saving current folder...\n",
      "\n",
      "Bye bye <^.^>\n",
      "\n",
      "ironclust run time 33.53s\n",
      "D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_waveforms\n",
      "D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\ironclust_phy\n",
      "Setting 'return_scaled' to False\n"
     ]
    }
   ],
   "source": [
    "# Run sorter\n",
    "sorter_name = 'ironclust'\n",
    "output_folder = Path.resolve(Path('..','results', sorter_name+'_output'))\n",
    "print(output_folder)\n",
    "sorting = si.run_sorter(sorter_name, rec, output_folder, verbose=True, remove_existing_folder=True)\n",
    "\n",
    "# Get waveforms\n",
    "waveform_folder = Path.resolve(Path('..','results', sorter_name+'_waveforms'))\n",
    "print(waveform_folder)\n",
    "si.extract_waveforms(rec, sorting, waveform_folder,\n",
    "    n_jobs=1, total_memory=\"10M\", max_spikes_per_unit=500, return_scaled=False, overwrite=True)\n",
    "\n",
    "# Export to Phy\n",
    "we = si.WaveformExtractor.load_from_folder(waveform_folder)\n",
    "phy_folder =  Path.resolve(Path('..','results', sorter_name+'_phy'))\n",
    "print(phy_folder)\n",
    "si.export_to_phy(we, output_folder=phy_folder, verbose=False, remove_if_exists=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('si_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e87c389955eb3b5496154ae0f9a13093fb0f1de7e15261958ba371a00cba5d1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
