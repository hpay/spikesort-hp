{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import platform\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import matplotlib.pylab as plt\n",
    "import spikeinterface.full as si    # may need to run pip install in the spikeinterface folder first\n",
    "import probeinterface as pi\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# import ipywidgets\n",
    "%matplotlib widget\n",
    "\n",
    "# Import my custom modules\n",
    "from src import spikeinterface_hp \n",
    "# from src import rhdutilities \n",
    "from src import load_probe_rhd \n",
    "import importlib  # Allow module reloads in case any changes were made after starting the kernel: importlib.reload(spikeinterface_hp)\n",
    "\n",
    "# Add path to kilosort2 and ironclust repos\n",
    "si.Kilosort2Sorter.set_kilosort2_path(Path.resolve(Path('../../Kilosort-2.0')))\n",
    "si.IronClustSorter.set_ironclust_path(Path.resolve(Path('../../ironclust')))\n",
    "\n",
    "# Print SI version\n",
    "print(f\"SpikeInterface version: {si.__version__}\")\n",
    "\n",
    "# Print list of installed sorters\n",
    "# print(si.installed_sorters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Make toy example recording data in the results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script False\n",
    "\n",
    "# Set paths that are used throughout: results and data\n",
    "results_path = Path.resolve(Path('..','results')) \n",
    "print(results_path)\n",
    "data_path = results_path/'toy_example_recording'\n",
    "print(data_path)\n",
    "\n",
    "# Make the toy example in the data folder\n",
    "if not data_path.exists():\n",
    "    recording_raw, sorting = si.toy_example(num_segments=1, duration=100, seed=1, num_channels=16, num_columns=2)\n",
    "    recording_raw.save(folder=data_path)\n",
    "    print('Created toy data')\n",
    "else:\n",
    "    print('Toy data already exists')\n",
    "\n",
    "recording_raw = si.load_extractor(data_path)\n",
    "recording_cmr = recording_raw # It is already filtered and common median filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Load REAL data from the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths that are used throughout: results and data\n",
    "results_path = Path('Z:/Hannah/ephys/project2/HC05_220819')   #  A 32 channel recording, shank A only\n",
    "# results_path = Path('Z:/Hannah/ephys/project2/test64b')    # A short 64 channel recording (all noise, no real spikes)\n",
    "data_path = [f for f in results_path.iterdir() if f.is_dir() and f.name.startswith('raw')] # subfolder starting with raw*. Should only be one!\n",
    "data_path = data_path[0] # Set data_path to the folder containing the intan.rhd file etc\n",
    "print(data_path)\n",
    "\n",
    "importlib.reload(spikeinterface_hp)\n",
    "recording_raw = spikeinterface_hp.read_intan_dat(data_path)\n",
    "\n",
    "# Load the probe for this file\n",
    "importlib.reload(load_probe_rhd)\n",
    "probe = load_probe_rhd.H6(data_path/'info.rhd', results_path/'probe.json')\n",
    "recording_raw = recording_raw.set_probe(probe, group_mode=\"by_shank\")\n",
    "\n",
    "# Visualizations/checks\n",
    "probe = recording_raw.get_probe() # sorts by index in .dat file\n",
    "print(probe.to_dataframe(complete=True).loc[:, ['x','y','contact_ids', 'shank_ids', 'device_channel_indices']])\n",
    "pi.plotting.plot_probe(probe, with_channel_index=True) \n",
    "# pi.plotting.plot_probe(probe, with_device_index=True) # Now the channel index matches the device index bc it was sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a built in probe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false # Don't run this cell!\n",
    "\n",
    "# Built-in probe\n",
    "manufacturer = 'cambridgeneurotech'\n",
    "probe_name = 'ASSY-236-H6'\n",
    "probe = pi.get_probe(manufacturer, probe_name)  \n",
    "\n",
    "# map channels to device indices\n",
    "mapping_to_device = [\n",
    "53,55,61,63,62,60,58,56,54,52,50,46,48,47,43,45,57,59,42,40,38,36,34,44,32,30,28,26,24,22,23,27,51,49,0,2,4,6,8,7,10,12,14,16,18,20,21,19,41,39,37,35,33,31,29,25,17,9,11,15,13,5,3,1\n",
    "]\n",
    "probe.set_device_channel_indices(mapping_to_device)\n",
    "# probe.wiring_to_device('ASSY-236>RHD2164') # Built-in\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "pi.plotting.plot_probe(probe, with_device_index=True, ax=ax) # with_contact_id=True\n",
    "pprint(probe.to_dataframe(complete=True).loc[:, ['x','y','contact_ids', 'shank_ids', 'device_channel_indices']])\n",
    "\n",
    "# Load the probeinterface object to the SI recording object:\n",
    "recording_raw = recording_raw.set_probe(probe, group_mode=\"by_shank\")\n",
    "\n",
    "# When loading the probe, it is automatically sorted by device indices (the order the data is stored on disk):\n",
    "probe_rec = recording_raw.get_probe()\n",
    "print(probe_rec.to_dataframe(complete=True).loc[:, [\"contact_ids\", \"shank_ids\", \"device_channel_indices\"]])\n",
    "print(\"Properties after loading the probe:\", list(recording_raw.get_property_keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bandpass filter and apply common median reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 10 minute segment for testing purposes\n",
    "# fs = recording_raw.get_sampling_frequency()\n",
    "# recording_raw = recording_raw.frame_slice(start_frame=0*fs, end_frame=300*fs)\n",
    "\n",
    "# Filter\n",
    "recording_f = si.highpass_filter(recording_raw, freq_min=300) # Not recommended to throw out high frequencies before sortin\n",
    "recording_cmr = si.common_reference(recording_f, reference='global', operator='median')\n",
    "\n",
    "# Plot the traces after applying CMR:\n",
    "# w = si.plot_timeseries({\"filt\": recording_f, \"common\": recording_cmr}, \n",
    "#   clim=(-1000, 1000), order_channel_by_depth=False,show_channel_ids=True, backend=\"ipywidgets\") #ipywidgets only works in browser - run jupyter notebook in anaconda prompt\n",
    "w = si.plot_timeseries({\"filt\": recording_f, \"common\": recording_cmr},\n",
    "    order_channel_by_depth=False, time_range=[10,11], channel_ids=range(16), show_channel_ids=True)\n",
    "# Note: if order_by_channel_depth=True, the order is messed up between the two inputs!\n",
    "\n",
    "# Cache the filtered recording to speed some things up later? and allow phy to load it?\n",
    "# recording_cmr_folder = Path('C:/Temp/spikeinterface')\n",
    "# while os.path.isdir(recording_cmr_folder): shutil.rmtree(recording_cmr_folder, ignore_errors=True)\n",
    "# recording_saved = recording_cmr.save(folder=recording_cmr_folder, n_jobs=-1, total_memory=\"2G\") # , n_jobs=-1, total_memory=\"10G\"\n",
    "# print(recording_cmr.get_binary_description()['file_paths'])\n",
    "\n",
    "# If it's already saved\n",
    "# recording_cmr = si.load_extractor(recording_cmr_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General sorting/waveform/phy settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform extractor settings\n",
    "ms_before = 1.5 # default 3\n",
    "ms_after = 2.5  # default 4\n",
    "max_spikes_per_unit = 500\n",
    "\n",
    "# export_to_phy setting\n",
    "max_ch_per_template = 8\n",
    "chunk_duration = '10s'\n",
    "n_jobs = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run spikesorting\n",
    "\n",
    "Note: make sure your startup.m file in Matlab doesn't change the current directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Kilosort2 params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_kilosort2_params = si.Kilosort2Sorter.default_params()\n",
    "pprint(default_kilosort2_params)\n",
    "# default_kilosort2_params['reorder'] = 0 # Can't access this?\n",
    "#TODO: increase batch size to avoid losing sparsely active cells?\n",
    "default_kilosort2_params['freq_min'] = 300            # SC setting: 150->300. Keep it on even if pre-filtering https://github.com/MouseLand/Kilosort/issues/276\n",
    "\n",
    "# default_kilosort2_params['minFR'] = 0.02              # Default in Matlab is 0.02, default in SI is 0.1\n",
    "# default_kilosort2_params['minfr_goodchannels'] = 0.02 # Default in Matlab is 0.02, default in SI is 0.1\n",
    "# default_kilosort2_params['NT'] = 64*1024+default_kilosort2_params['ntbuff'] # SC increased to 4*64*1024+ope.ntbuff (128)\n",
    "\n",
    "# default_kilosort2_params['car'] = False               # Already did this\n",
    "# default_kilosort2_params['nfilt_factor'] = 8 # SC increased from 4 to 8 # max number of clusters per good channel (even temporary ones)\n",
    "\n",
    "# default_kilosort2_params['detectArtifacts'] = False\n",
    "# ops.nfilt_factor        = 8;    % (SC changed from 4) % max number of clusters per good channel (even temporary ones)\n",
    "# ops.ntbuff              = 128;  % (SC changed from 64) % samples of symmetrical buffer for whitening and spike detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run kilosort2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sorter\n",
    "sorter_name = 'kilosort2'\n",
    "sorting_folder = results_path/(sorter_name+'_output')\n",
    "sorting = si.run_sorter(sorter_name, recording_cmr, sorting_folder, verbose=True, remove_existing_folder=True) # **default_kilosort2_params. Use recording_cmr instead??\n",
    "print(sorting_folder)\n",
    "print(sorting)\n",
    "os.remove(sorting_folder/'temp_wh.dat') # Remove large temporary file\n",
    "\n",
    "# Save sorting in spike interface .npz format\n",
    "sorting_save_path = results_path/(sorter_name+'_si_output')\n",
    "sorting.save(folder=sorting_save_path)\n",
    "print(sorting_save_path)\n",
    "\n",
    "# TODO: Delete original sorting folder after it is exported, either to Phy, or skip the waveforms/phy export, and save sorting as npz format?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false\n",
    "\n",
    "# To export the original sortings to phy:\n",
    "sorter_name = 'kilosort2'\n",
    "output_folder = results_path/(sorter_name+'_si_output')\n",
    "\n",
    "# Extract waveforms\n",
    "waveform_folder = results_path/(sorter_name+'_waveforms')\n",
    "print(waveform_folder)\n",
    "sorting = si.load_extractor(output_folder) # Load the sorting results (only needed if picking up from here)\n",
    "we = si.extract_waveforms(recording_raw, sorting, waveform_folder, return_scaled=True, overwrite=True, # TODO check effect of raw or cmr??\n",
    "    n_jobs=n_jobs, chunk_duration=chunk_duration, max_spikes_per_unit=max_spikes_per_unit,ms_before=ms_before, ms_after=ms_after) #total_memory=\"10M\",  \n",
    "    #NOTE: return_scaled: If True and recording has gain_to_uV/offset_to_uV properties, waveforms are converted to uV.\n",
    "\n",
    "# Export to phy\n",
    "we = si.WaveformExtractor.load_from_folder(waveform_folder) # Load the waveforms results (only needed if picking up from here)\n",
    "we.recording = recording_raw # Just do this so that the path to the raw .dat file is stored in params.py\n",
    "phy_folder =  results_path/(sorter_name+'_phy')\n",
    "print(phy_folder)\n",
    "si.export_to_phy(we, output_folder=phy_folder,remove_if_exists=True,copy_binary=False,compute_amplitudes=True,\n",
    "    max_channels_per_template=max_ch_per_template, chunk_duration=chunk_duration, n_jobs=n_jobs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Ironclust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sorter\n",
    "sorter_name = 'ironclust'\n",
    "sorting_folder = results_path/(sorter_name+'_output')\n",
    "sorting = si.run_sorter(sorter_name, recording_raw, sorting_folder, verbose=True, remove_existing_folder=True) # filter=False, detect_threshold=1\n",
    "print(sorting)\n",
    "\n",
    "# Save sorting in spike interface .npz format\n",
    "sorting_folder = results_path/(sorter_name+'_si_output')\n",
    "sorting.save(folder=sorting_folder)\n",
    "print(sorting_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "# Get waveforms\n",
    "waveform_folder = results_path/(sorter_name+'_waveforms')\n",
    "we = si.extract_waveforms(recording_cmr, sorting, waveform_folder,return_scaled=True, overwrite=True,\n",
    "    n_jobs=n_jobs, chunk_duration=chunk_duration, max_spikes_per_unit=max_spikes_per_unit,ms_before=ms_before, ms_after=ms_after)\n",
    "\n",
    "# Export to Phy\n",
    "phy_folder = results_path/(sorter_name+'_phy')\n",
    "si.export_to_phy(we, sorting_folder=phy_folder,remove_if_exists=True,copy_binary=False,compute_amplitudes=True,\n",
    "    max_channels_per_template=max_ch_per_template, chunk_duration=chunk_duration, n_jobs=n_jobs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Quality metrics for KS sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get quality metrics for all KS sorting\n",
    "waveform_folder = results_path/'kilosort2_waveforms'\n",
    "we = si.WaveformExtractor.load_from_folder(waveform_folder) # Load the waveforms results (only needed if picking up from here)\n",
    "metric_names=['snr', 'isi_violation', 'amplitude_cutoff','isolation_distance','firing_rate']\n",
    "# NOTE: isi_violations_rate: \"Rate of contaminating spikes as a fraction of overall rate. Higher values indicate more contamination\" (== #sp_bad/#sp_total)\n",
    "# Q: how to set bin width and refractory period for ISI violations?\n",
    "\n",
    "qm = si.compute_quality_metrics(we,load_if_exists=True,metric_names=metric_names)\n",
    "qm = qm.drop('isi_violations_ratio')\n",
    "score_filename = results_path/'si_qm.csv'\n",
    "qm.to_csv(score_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the two sortings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sortings from .npz format (SI preferred):\n",
    "sorting_ks = si.load_extractor(results_path/('kilosort2_si_output')) # Load the sorting results (only needed if picking up from here)\n",
    "sorting_ic = si.load_extractor(results_path/('ironclust_si_output')) # Load the sorting results (only needed if picking up from here)\n",
    "\n",
    "# Load sortings - from kilosort2/ironclust output folder\n",
    "# sorting_ks = si.read_kilosort(results_path/'kilosort2_output')\n",
    "# sorting_ic = si.read_mda_sorting(results_path/'ironclust_output'/'tmp'/'firings.mda',sampling_frequency=recording_raw.get_sampling_frequency()) #_get_result_from_folder? read_mda_sorting\n",
    "\n",
    "# Load sortings - from phy folder\n",
    "# sorting_ks = si.read_phy(results_path/'kilosort2_phy') # Alternate if saved as phy\n",
    "# sorting_ic = si.read_phy(results_path/'ironclust_phy') # Alternate if saved as phy\n",
    "\n",
    "sub = '' #add onto output folders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Compare with one as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# agreement_df.to_csv(score_filename)\n",
    "match_to_ks = match_to_ks.rename('match')\n",
    "match_to_ks.to_csv(match_filename) # header=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare two sorters\n",
    "comp_ks_ic = si.compare_two_sorters(sorting1=sorting_ks, sorting2=sorting_ic)  # returns SortingComparison object\n",
    "print('Relative to Kilosort2:')\n",
    "match_to_ks = comp_ks_ic.hungarian_match_12\n",
    "match_to_ic = comp_ks_ic.hungarian_match_21\n",
    "\n",
    "# Save all the best agreement scores for each KS cell (not necessarily the matched scores)\n",
    "# score_df = pd.DataFrame({'ks_ind': range(len(match_to_ks)), 'ic_ind':match_to_ks,'score': comp_ks_ic.agreement_scores.max(axis=1) })\n",
    "score_filename = results_path/'si_score_all.csv'\n",
    "comp_ks_ic.agreement_scores.to_csv(score_filename)\n",
    "\n",
    "# Return the agreement scores just for the matching units\n",
    "# agreement_scores = comp_ks_ic.agreement_scores\n",
    "# ks_ind = np.nonzero([match_to_ks!=-1])[1]\n",
    "# ic_ind = match_to_ks.to_numpy()\n",
    "# ic_ind = ic_ind[match_to_ks!=-1].astype(int)\n",
    "# agreement_scores=agreement_scores.to_numpy()\n",
    "# agreement_scores_match = agreement_scores[(ks_ind,ic_ind)]\n",
    "# agreement_df = pd.DataFrame({'ks_ind': ks_ind, 'ic_ind': ic_ind, 'score':  agreement_scores_match} )\n",
    "# pprint(agreement_df)\n",
    "\n",
    "# score_filename = results_path/'si_score_match.csv'\n",
    "# agreement_df.to_csv(score_filename)\n",
    "match_to_ks = match_to_ks.rename('match')\n",
    "match_filename = results_path/'si_match.csv'\n",
    "match_to_ks.to_csv(match_filename) # header=False\n",
    "\n",
    "# Select only the matched units from the kilosort sorting\n",
    "ks_ind = np.nonzero([match_to_ks!=-1])[1]\n",
    "print(ks_ind)\n",
    "sorting_clean = sorting_ks.select_units(ks_ind)\n",
    "print(sorting_clean)\n",
    "\n",
    "# Get waveforms\n",
    "waveform_folder = results_path/('clean_waveforms'+sub)\n",
    "we = si.extract_waveforms(recording_cmr, sorting_clean, waveform_folder,return_scaled=True, overwrite=True,\n",
    "    n_jobs=n_jobs, chunk_duration=chunk_duration, max_spikes_per_unit=max_spikes_per_unit,ms_before=ms_before, ms_after=ms_after)\n",
    "\n",
    "# Export to Phy\n",
    "phy_folder = results_path/('clean_phy'+sub)\n",
    "we.recording = recording_raw # Just do this so that the path to the raw .dat file is stored in params.py\n",
    "si.export_to_phy(we, output_folder=phy_folder,remove_if_exists=True,copy_binary=False,compute_amplitudes=True,\n",
    "    max_channels_per_template=max_ch_per_template, chunk_duration=chunk_duration, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Find consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false \n",
    "comp_intersection = si.compare_multiple_sorters(sorting_list=[sorting_ks, sorting_ic],\n",
    "    name_list=['ks', 'ic'], spiketrain_mode='intersection',n_jobs=-1)\n",
    "\n",
    "output_folder_intersect = results_path/('intersect_output'+sub)\n",
    "sorting_agreement = comp_intersection.get_agreement_sorting(minimum_agreement_count=2)\n",
    "sorting_agreement = sorting_agreement.save(folder=output_folder_intersect)\n",
    "\n",
    "# Get waveforms\n",
    "waveform_folder = results_path/('intersect_waveforms'+sub)\n",
    "si.extract_waveforms(recording_cmr, sorting_agreement, waveform_folder,ms_before=ms_before, ms_after=ms_after,\n",
    "    n_jobs=n_jobs, chunk_duration=chunk_duration, max_spikes_per_unit=max_spikes_per_unit, return_scaled=True, overwrite=True)\n",
    "we = si.WaveformExtractor.load_from_folder(waveform_folder)\n",
    "\n",
    "# Export to Phy\n",
    "phy_folder = results_path/('intersect_phy'+sub)\n",
    "we.recording = recording_raw # Just do this so that the path to the raw .dat file is stored in params.py\n",
    "si.export_to_phy(we, output_folder=phy_folder,remove_if_exists=False,copy_binary=False,compute_amplitudes=True,\n",
    "    max_channels_per_template=max_ch_per_template, chunk_duration=chunk_duration, n_jobs=n_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Load union and intersects\n",
    "output_folder_intersect = results_path/'intersect_output'\n",
    "sorting_agreement = si.load_extractor(output_folder_intersect)\n",
    "print('Units in agreement, intersect:', sorting_agreement.get_unit_ids())\n",
    "\n",
    "# Plot matching results\n",
    "# np.close('all')\n",
    "fig,ax = plt.subplots(1,1,figsize=[1,3])\n",
    "ax.axis('equal')\n",
    "w = si.plot_multicomp_agreement(comp_intersection,ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Quality metrics & automatic curation for single sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "waveform_folder = results_path/'kilosort2_waveforms'\n",
    "\n",
    "# Load waveforms\n",
    "we = si.WaveformExtractor.load_from_folder(waveform_folder) # Only needed if picking up from here\n",
    "\n",
    "# Specifiy quality metrics\n",
    "print(si.get_quality_metric_list())\n",
    "metric_names=['snr', 'isi_violation', 'amplitude_cutoff','isolation_distance','firing_rate']\n",
    "# NOTE: isi_violations_rate: \"Rate of contaminating spikes as a fraction of overall rate. Higher values indicate more contamination\" (== #sp_bad/#sp_total)\n",
    "# Q: how to set bin width and refractory period for ISI violations?\n",
    "\n",
    "# Compute quality metrics\n",
    "qm = si.compute_quality_metrics(we,load_if_exists=True,metric_names=metric_names)\n",
    "pprint(qm)\n",
    "\n",
    "# Plot quality metrics\n",
    "si.plot_quality_metrics(we, include_metrics=[\"amplitude_cutoff\", \"isi_violations_rate\",\"firing_rate\"])\n",
    "\n",
    "# Screen sorting based on quality metrics\n",
    "firing_rate_cutoff = 50\n",
    "isi_viol_thresh =  0.1 # 0.2 is KS2 default\n",
    "amplitude_cutoff_thresh = 0.05\n",
    "our_query = f\"firing_rate < {firing_rate_cutoff} & isi_violations_rate < {isi_viol_thresh} & amplitude_cutoff < {amplitude_cutoff_thresh} \"\n",
    "\n",
    "qm_keep = qm.query(our_query)\n",
    "keep_unit_ids = qm_keep.index.values\n",
    "sorting_clean = we.sorting.select_units(keep_unit_ids)\n",
    "print(sorting)\n",
    "print(sorting_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false # don't run this cell!\n",
    "\n",
    "# Launch Phy\n",
    "phy_folder = results_path/'clean_phy'\n",
    "from phy.apps.template import template_gui\n",
    "template_gui(phy_folder/'params.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parking lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false # don't run this cell!\n",
    "\n",
    "# Check data type of .npy file\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "# file = Path(r\"D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\kilosort2_waveforms\\spike_amplitudes\\amplitude_segment_0.npy\")\n",
    "file = Path(r\"Z:\\Hannah\\ephys\\project2\\HC05_220819\\intersect_waveforms\\spike_amplitudes\\amplitude_segment_0.npy\")\n",
    "print(file)\n",
    "temp = np.load(file)\n",
    "print(type(temp))\n",
    "print(type(temp[0]))\n",
    "pprint(temp)\n",
    "np.shape(temp)\n",
    "\n",
    "Check channel gains in recording\n",
    "print(recording_raw.get_channel_gains())\n",
    "print(recording_cmr.get_channel_gains())\n",
    "print(phy_folder)\n",
    "\n",
    "print(list(recording_raw.get_property_keys()))\n",
    "print(list(sorting_agreement_intersect.get_property_keys()))\n",
    "pprint(sorting_agreement_intersect.get_property(key='avg_agreement'))\n",
    "pprint(sorting_agreement_intersect.get_property(key='unit_ids'))\n",
    "\n",
    "\n",
    "# Example of loading the curated phy output back in and selecting units marked \"good\"\n",
    "sorting_phy = si.PhySortingExtractor('path-to-phy-folder', exclude_cluster_groups=['noise'])\n",
    "good_ks_units = []\n",
    "for u in sorting_phy.get_unit_ids():\n",
    "    if sorting_phy.get_unit_property(u, 'KSLabel') == 'good':\n",
    "        good_ks_units.append(u)        \n",
    "sorting_ks_good = sorting_phy.select_units(good_ks_units)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e87c389955eb3b5496154ae0f9a13093fb0f1de7e15261958ba371a00cba5d1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
