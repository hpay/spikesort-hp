{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import platform\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import matplotlib.pylab as plt\n",
    "import spikeinterface.full as si    # may need to run pip install in the spikeinterface folder first\n",
    "import probeinterface as pi\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# import ipywidgets\n",
    "%matplotlib widget\n",
    "\n",
    "# Import my custom modules\n",
    "from src import spikeinterface_hp \n",
    "# from src import rhdutilities \n",
    "from src import load_probe_rhd \n",
    "import importlib  # Allow module reloads in case any changes were made after starting the kernel: importlib.reload(spikeinterface_hp)\n",
    "\n",
    "# Add path to kilosort2 and ironclust repos\n",
    "si.Kilosort2Sorter.set_kilosort2_path(Path.resolve(Path('../../Kilosort-2.0')))\n",
    "si.IronClustSorter.set_ironclust_path(Path.resolve(Path('../../ironclust')))\n",
    "\n",
    "# Print SI version\n",
    "print(f\"SpikeInterface version: {si.__version__}\")\n",
    "\n",
    "# Print list of installed sorters\n",
    "# print(si.installed_sorters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths that are used throughout: results and data\n",
    "# results_path = Path('Z:/Hannah/ephys/project2/HC07_221014') \n",
    "# results_path = Path('Z:/Hannah/ephys/project2/HC07_221015') \n",
    "# results_path = Path('Z:/Hannah/ephys/project2/HC07_221019')  Y\n",
    "# results_path = Path('Z:/Hannah/ephys/project2/HC07_221021')  Y\n",
    "# results_path = Path('Z:/Hannah/ephys/project2/HC07_221024')\n",
    "\n",
    "results_path = Path('Z:/Hannah/ephys/project2/HC05_220819')   #  A 32 channel recording, shank A only\n",
    "\n",
    "data_path = [f for f in results_path.iterdir() if f.is_dir() and f.name.startswith('raw')] # subfolder starting with raw*. Should only be one!\n",
    "data_path = data_path[0] # Set data_path to the folder containing the intan.rhd file etc\n",
    "print(data_path)\n",
    "\n",
    "importlib.reload(spikeinterface_hp)\n",
    "recording_raw = spikeinterface_hp.read_intan_dat(data_path)\n",
    "\n",
    "# Load the probe for this file - should automatically deal with missing channels!\n",
    "importlib.reload(load_probe_rhd)\n",
    "probe = load_probe_rhd.H6(data_path/'info.rhd', results_path/'probe.json')\n",
    "recording_raw = recording_raw.set_probe(probe, group_mode=\"by_shank\")\n",
    "\n",
    "# Visualizations/checks\n",
    "probe = recording_raw.get_probe() # sorts by index in .dat file\n",
    "print(probe.to_dataframe(complete=True).loc[:, ['x','y','contact_ids', 'shank_ids', 'device_channel_indices']])\n",
    "# pi.plotting.plot_probe(probe, with_channel_index=True) \n",
    "pi.plotting.plot_probe(probe, with_device_index=True) # Now the channel index matches the device index bc it was sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bandpass filter and apply common median reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter\n",
    "recording_f = si.highpass_filter(recording_raw, freq_min=300) # Not recommended to throw out high frequencies before sortin\n",
    "recording_cmr = si.common_reference(recording_f, reference='global', operator='median')\n",
    "\n",
    "# Plot the traces after applying CMR:\n",
    "w = si.plot_timeseries({\"filt\": recording_f, \"common\": recording_cmr},\n",
    "    order_channel_by_depth=True, time_range=[10,11], channel_ids=range(16), show_channel_ids=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General sorting/waveform/phy settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform extractor settings\n",
    "ms_before = 1.5 # default 3\n",
    "ms_after = 2.5  # default 4\n",
    "max_spikes_per_unit = 500\n",
    "\n",
    "# export_to_phy setting\n",
    "max_ch_per_template = 8\n",
    "chunk_duration = '10s'\n",
    "n_jobs = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Kilosort2 sorting (do this separately in matlab!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To export the original sortings to phy:\n",
    "sorting_ks = si.read_kilosort(results_path/'kilosort2_output')\n",
    "\n",
    "# Extract waveforms\n",
    "waveform_folder = results_path/('kilosort2_waveforms')\n",
    "print(waveform_folder)\n",
    "we = si.extract_waveforms(recording_cmr, sorting_ks, waveform_folder, return_scaled=True, overwrite=True, # TODO check effect of raw or cmr??\n",
    "    n_jobs=n_jobs, chunk_duration=chunk_duration, max_spikes_per_unit=max_spikes_per_unit,ms_before=ms_before, ms_after=ms_after) #total_memory=\"10M\",  \n",
    "    #NOTE: return_scaled: If True and recording has gain_to_uV/offset_to_uV properties, waveforms are converted to uV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Ironclust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run sorter\n",
    "sorter_name = 'ironclust'\n",
    "sorting_folder = results_path/(sorter_name+'_output')\n",
    "sorting_ic = si.run_sorter(sorter_name, recording_raw, sorting_folder, verbose=True, remove_existing_folder=True) # filter=False, detect_threshold=1\n",
    "print(sorting_ic)\n",
    "\n",
    "# Save sorting in spike interface .npz format\n",
    "sorting_folder = results_path/(sorter_name+'_si_output')\n",
    "sorting_ic.save(folder=sorting_folder)\n",
    "print(sorting_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Get Quality metrics for KS sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get quality metrics for all KS sorting\n",
    "waveform_folder = results_path/'kilosort2_waveforms'\n",
    "we = si.WaveformExtractor.load_from_folder(waveform_folder) # Load the waveforms results (only needed if picking up from here)\n",
    "metric_names=['snr', 'isi_violation', 'amplitude_cutoff','isolation_distance','firing_rate']\n",
    "# NOTE: isi_violations_rate: \"Rate of contaminating spikes as a fraction of overall rate. Higher values indicate more contamination\" (== #sp_bad/#sp_total)\n",
    "# Q: how to set bin width and refractory period for ISI violations?\n",
    "\n",
    "qm = si.compute_quality_metrics(we,load_if_exists=True,metric_names=metric_names)\n",
    "\n",
    "score_filename = results_path/'si_qm.csv'\n",
    "qm.to_csv(score_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with Kilosort2 as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load sortings from .npz format (SI preferred):\n",
    "sorting_ks = si.read_kilosort(results_path/'kilosort2_output')\n",
    "sorting_ic = si.load_extractor(results_path/'ironclust_si_output') # Load the sorting results (only needed if picking up from here)\n",
    "# sorting_ks = si.read_phy(results_path/'kilosort2_phy') # Alternate if saved as phy\n",
    "\n",
    "sub = '' #add onto output folders\n",
    "\n",
    "# Compare two sorters\n",
    "comp_ks_ic = si.compare_two_sorters(sorting1=sorting_ks, sorting2=sorting_ic)  # returns SortingComparison object\n",
    "print('Relative to Kilosort2:')\n",
    "match_to_ks = comp_ks_ic.hungarian_match_12\n",
    "match_to_ic = comp_ks_ic.hungarian_match_21\n",
    "\n",
    "# Save all the best agreement scores for each KS cell (not necessarily the matched scores)\n",
    "# score_df = pd.DataFrame({'ks_ind': range(len(match_to_ks)), 'ic_ind':match_to_ks,'score': comp_ks_ic.agreement_scores.max(axis=1) })\n",
    "score_filename = results_path/'si_score_all.csv'\n",
    "comp_ks_ic.agreement_scores.to_csv(score_filename)\n",
    "\n",
    "# Export the matching IC units relative to KS\n",
    "match_to_ks = match_to_ks.rename('match')\n",
    "match_filename = results_path/'si_match.csv'\n",
    "match_to_ks.to_csv(match_filename) # header=False\n",
    "\n",
    "# Select only the matched units from the kilosort sorting\n",
    "ks_ind = np.nonzero([match_to_ks!=-1])[1]\n",
    "print(ks_ind)\n",
    "sorting_clean = sorting_ks.select_units(ks_ind)\n",
    "print(sorting_clean)\n",
    "\n",
    "\n",
    "# Get waveforms\n",
    "waveform_folder = results_path/('clean_waveforms'+sub)\n",
    "we = si.extract_waveforms(recording_cmr, sorting_clean, waveform_folder,return_scaled=True, overwrite=True,\n",
    "    n_jobs=n_jobs, chunk_duration=chunk_duration, max_spikes_per_unit=max_spikes_per_unit,ms_before=ms_before, ms_after=ms_after)\n",
    "\n",
    "\n",
    "chunk_duration = '1s'\n",
    "max_ch_per_template = 1\n",
    "\n",
    "# Export to Phy\n",
    "phy_folder = results_path/('clean_phy'+sub)\n",
    "we.recording = recording_raw # Just do this so that the path to the raw .dat file is stored in params.py\n",
    "si.export_to_phy(we, output_folder=phy_folder,remove_if_exists=True,copy_binary=False,compute_amplitudes=True,\n",
    "    max_channels_per_template=max_ch_per_template, chunk_duration=chunk_duration, n_jobs=n_jobs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Quality metrics & automatic curation for single sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "waveform_folder = results_path/'kilosort2_waveforms'\n",
    "\n",
    "# Load waveforms\n",
    "we = si.WaveformExtractor.load_from_folder(waveform_folder) # Only needed if picking up from here\n",
    "\n",
    "# Specifiy quality metrics\n",
    "print(si.get_quality_metric_list())\n",
    "metric_names=['snr', 'isi_violation', 'amplitude_cutoff','isolation_distance','firing_rate']\n",
    "# NOTE: isi_violations_rate: \"Rate of contaminating spikes as a fraction of overall rate. Higher values indicate more contamination\" (== #sp_bad/#sp_total)\n",
    "# Q: how to set bin width and refractory period for ISI violations?\n",
    "\n",
    "# Compute quality metrics\n",
    "qm = si.compute_quality_metrics(we,load_if_exists=True,metric_names=metric_names)\n",
    "pprint(qm)\n",
    "\n",
    "# Plot quality metrics\n",
    "si.plot_quality_metrics(we, include_metrics=[\"amplitude_cutoff\", \"isi_violations_rate\",\"firing_rate\"])\n",
    "\n",
    "# Screen sorting based on quality metrics\n",
    "firing_rate_cutoff = 50\n",
    "isi_viol_thresh =  0.1 # 0.2 is KS2 default\n",
    "amplitude_cutoff_thresh = 0.05\n",
    "our_query = f\"firing_rate < {firing_rate_cutoff} & isi_violations_rate < {isi_viol_thresh} & amplitude_cutoff < {amplitude_cutoff_thresh} \"\n",
    "\n",
    "qm_keep = qm.query(our_query)\n",
    "keep_unit_ids = qm_keep.index.values\n",
    "sorting_clean = we.sorting.select_units(keep_unit_ids)\n",
    "print(sorting)\n",
    "print(sorting_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Launch phy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%script false # don't run this cell!\n",
    "\n",
    "# Launch Phy\n",
    "phy_folder = results_path/'clean_phy'\n",
    "from phy.apps.template import template_gui\n",
    "template_gui(phy_folder/'params.py')\n",
    "Parking lot\n",
    "%%script false # don't run this cell!\n",
    "\n",
    "# Check data type of .npy file\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "# file = Path(r\"D:\\hannah\\Dropbox\\code\\spikesort\\spikesort-hp\\results\\kilosort2_waveforms\\spike_amplitudes\\amplitude_segment_0.npy\")\n",
    "file = Path(r\"Z:\\Hannah\\ephys\\project2\\HC05_220819\\intersect_waveforms\\spike_amplitudes\\amplitude_segment_0.npy\")\n",
    "print(file)\n",
    "temp = np.load(file)\n",
    "print(type(temp))\n",
    "print(type(temp[0]))\n",
    "pprint(temp)\n",
    "np.shape(temp)\n",
    "\n",
    "\n",
    "# Example of loading the curated phy output back in and selecting units marked \"good\"\n",
    "sorting_phy = si.PhySortingExtractor('path-to-phy-folder', exclude_cluster_groups=['noise'])\n",
    "good_ks_units = []\n",
    "for u in sorting_phy.get_unit_ids():\n",
    "    if sorting_phy.get_unit_property(u, 'KSLabel') == 'good':\n",
    "        good_ks_units.append(u)        \n",
    "sorting_ks_good = sorting_phy.select_units(good_ks_units)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:50:36) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e87c389955eb3b5496154ae0f9a13093fb0f1de7e15261958ba371a00cba5d1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
